{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS5V_td3FFH2"
      },
      "source": [
        "\n",
        "# LIBRERIAS A **IMPORTAR**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RueXycvIy1pd"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO9UGoJM5CVG"
      },
      "outputs": [],
      "source": [
        "\n",
        "%cd /gdrive/MyDrive/jpg/\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skWRc_5fE6bN"
      },
      "outputs": [],
      "source": [
        "#from skimage import io\n",
        "from google.colab import files #para importar las imagenes\n",
        "\n",
        "import os #para poder hacer el ls\n",
        "\n",
        "from google.colab.patches import cv2 #para ver si un archivo es realmente una imagen\n",
        "\n",
        "\n",
        "import numpy as np#para varias cosas, relacionadas con generar vectores de numeros que sean 1, 0, o ruido\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt #para poder hacer plot de los vectores como imagenes\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras# para poder hacer la red de neuronas\n",
        "\n",
        "\n",
        "import imageio\n",
        "import glob\n",
        "#las dos de arriba para hacer los gif\n",
        "\n",
        "from PIL import Image #para hacer gif mas grandes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQZUFOCUGqQs"
      },
      "source": [
        "# IMPORTAMOS LAS FOTOS\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C60uFgwtIfA1"
      },
      "source": [
        "\n",
        "\n",
        "# Procesamos las fotos para meterlas en un array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ib80wlpGl9r"
      },
      "outputs": [],
      "source": [
        "from skimage import color\n",
        "from skimage import io\n",
        "i=0\n",
        "#input= \"/content\" #donde se han cargado las imagenes\n",
        "input=\"/gdrive/MyDrive/jpg\"\n",
        "files_names = os.listdir(input) #sacamos todos los elementos de la carpeta actual (hacemos un ls)\n",
        "coches=[] #creamos una lista vacia#\n",
        "\n",
        "for f in files_names:\n",
        "    \n",
        "    imagepath = input + \"/\" + f #\n",
        "    #image = cv2.imread(imagepath)#leemos la foto\n",
        "    #if image is not  None: #comprobamos que es una imagen\n",
        "      #coche= color.rgb2gray(io.imread(f))#importante dividir entre 255 #la cargamos en blanco y negro\n",
        "      #coche=np.resize(coche,(44,44))# le cambiamos el formato a 44x44 pixeles\n",
        "      #en este caso no hace falta porque vamos a \n",
        "      #nuevos coches\n",
        "    i=i+1\n",
        "    if (i%100)==0:\n",
        "        print(i)\n",
        "    #im = Image.open(imagepath).convert('L')PARA BLANCO Y NEGRO\n",
        "    im = Image.open(imagepath)#.convert('L')\n",
        "    #Z=(cv2.resize(np.float32(im), (104, 104))-127.5)/127.5\n",
        "    Z=cv2.resize(np.float32(im), (56, 56))/255\n",
        "    #((trainX-127.5)/127.5)\n",
        "    coches.append(Z) #lo guardo en la lista de coches\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P64iK6s6lhbg"
      },
      "source": [
        "# Funcion de manrique para la visualizacion de imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvGoniaMlnIN"
      },
      "outputs": [],
      "source": [
        "# The plotting function for images of dimension 7x7\n",
        "dim=56\n",
        "def view_samples(samples, m, n):\n",
        "    fig, axes = plt.subplots(figsize=(10, 10), nrows=m, ncols=n, sharey=True, sharex=True)\n",
        "    for ax, img in zip(axes.flatten(), samples):\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "        #im = ax.imshow(1-img.reshape((dim,dim)), cmap='Greys_r')  #original\n",
        "        #im = ax.imshow(img.reshape((dim,dim)), cmap='Greys_r')  \n",
        "        im = ax.imshow(img.reshape((dim,dim,3)))  \n",
        "    return fig, axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4HRyZpxOrU1"
      },
      "source": [
        "# Datos necesarios para la GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW9VfECxK6f1"
      },
      "outputs": [],
      "source": [
        "batch_size=32#TODO ir probando a cambiar el batch size.# en realidad el batch size seria el doble, porque hay batchsize correctas y batchsize incorrectas, asi que el numero de imagenes con el que vamos a entrenar a la red cada vez es el doble\n",
        "#real = np.ones((batch_size/2, 1))#numero de imagenes correctas que  tendra cada batch \n",
        "#fake = np.zeros((batch_size/2, 1))#numero de imagenes incorrectas que  tendra cada batch \n",
        "img_width=56\n",
        "img_height=56\n",
        "img_channels=3 #1= blanco y negro,3 = rgb\n",
        "lr=0.1 #Learning rate\n",
        "#view_samples(coches, 2,5) # para visualizar las imagenes\n",
        "epochs=16000 # epochs para entrenar la GAN\n",
        "show_interval=200 #cada cuanto se visualizan las imagenes cuando estemos entrenando la GAN  \n",
        "tam_dataset=8195\n",
        "neural_input=400"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29Qss_-3nM8A"
      },
      "source": [
        "# Creamos el generador de imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0IKYQFboQmf"
      },
      "source": [
        "Estructura:100->11X11X128=(15488)->128imagenes() 11x11-> normalizarlo-> 64 imagenes 22x22-> normalizamos -> 44X44 con depth de 1, blanco y negro, supongo que para imagenes en color sera 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAqVx45KurNn"
      },
      "source": [
        "# ESTRUCTURA:\n",
        "# 400->25088->14x14(128)->28x28(84)->56x56(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYxWhryjlLTg"
      },
      "outputs": [],
      "source": [
        " #input \n",
        "generator= keras.models.Sequential([\n",
        "  keras.layers.Dense(14*14*128, input_shape=[neural_input]),#reescalamos de 100 a 11*11*128=15488\n",
        "\n",
        "  keras.layers.Reshape([14,14,128]),#hacemos imagenes 11*11 con una depth de 128\n",
        "  keras.layers.BatchNormalization(),#lo normalizamos\n",
        "  keras.layers.Conv2DTranspose(84,kernel_size=5,strides=2,padding=\"same\",activation=\"selu\"),#red convolucional transpuesta-> depth de 64,cada dimension la multiplica *2(stride=2) -> 22X22, pero solo con depth 64, aplicamos filtros 5*5\n",
        "  keras.layers.BatchNormalization(),#lo normalizamos\n",
        "  keras.layers.Conv2DTranspose(3,kernel_size=5,strides=2,padding=\"same\",activation='tanh'),#44*44(1)\n",
        "\n",
        "\n",
        "\n",
        "],name=\"Generador\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CRjkeyMwysX"
      },
      "source": [
        "El unico problema es que crea las imagenes, y cada pixel en vez de ir de 0 a 1, en este caso va de -1 a 1, asi que hay dos opciones, canviar la salida del generador para que vaya de 0 a 1, o nuestras imagenes cambiarlas para que vayan de -1 a 1, que creo que hare esto. \n",
        "PARA ello a cada pixel le multiplico *2 y despues le resto 1.\n",
        "Cuando ya tenga las imagenes, para visualizarlas seria al reves pero en orden inverso(suposicion mia, IMPORTANTE COMPROBAR). \n",
        "Sumarle 1 y despues dividirlo entre 2\n",
        "dividir entre 2 y despues sumarle 1 MAL MAL MAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiylPY1JwgKw"
      },
      "source": [
        "# Creamos el discriminador de imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-P_nF1WwnTf"
      },
      "source": [
        "Estructura->input 44x44(1)->  64 filtros 5x5(en vez de usar maxpooling, hago stride 2 IMPORTANTE COMPROBAR CUAL ES MEJRO)-> 22x22 y hago dropout(consultar por que IMPORTANTE COMPROBAR)-> 128 filtros 5x5 para imagenes 22x22 con strides de 2 asi que se queda 11x11-> dropout de 0.4-> layer plana de 15488 y despues de 1.(IMPORTANTE COMPROBAR meter alguna layer plana intermedia)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmSFg5V21SFQ"
      },
      "source": [
        "# ESTRUCTURA->56x56(3)->28X28(84)->14x14(162)->31752->1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqm6Ap4HovTH"
      },
      "outputs": [],
      "source": [
        "\n",
        "discriminator= keras.models.Sequential([\n",
        "  keras.layers.Conv2D(84,kernel_size=5,strides=2,padding=\"same\",activation=keras.layers.LeakyReLU(0.2),input_shape=[56,56,3]),\n",
        "  keras.layers.Dropout(0.3),\n",
        "  keras.layers.Conv2D(128,kernel_size=5,strides=2,padding=\"same\",activation=keras.layers.LeakyReLU(0.2)),\n",
        "  keras.layers.Dropout(0.3),#antes 0.4\n",
        "  keras.layers.Flatten(),\n",
        "  #keras.layers.Dense(2003, activation=\"selu\"),\n",
        "  keras.layers.Dense(203, activation=\"selu\"),\n",
        "  keras.layers.Dense(1,activation=\"sigmoid\")\n",
        "  \n",
        "],name='Discriminador')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtEextAuTJca"
      },
      "outputs": [],
      "source": [
        "X_train2 = np.expand_dims(coches, axis=4)# le reducimos una dimension y lo dejamo preparado para poder hacer el reshape(multiplicarlo*2 y despues restarle uno)\n",
        "X_train=X_train2.reshape(8195,56,56,3)\n",
        "\n",
        "\n",
        "#X_train=trainX\n",
        "#X_train=  X_train.reshape(-1,28,28,1)*2.-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY4NCYZiZu7v"
      },
      "outputs": [],
      "source": [
        "print(discriminator.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMtgOWRSbmx"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kodsqkcbV2rC"
      },
      "source": [
        "el generador no hace falta compilarlo porque solo se entrenara gracias a la gan, pero no lo entrenamos a parte como el drscriminador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzdnTjRtSktB"
      },
      "outputs": [],
      "source": [
        "GAN = keras.models.Sequential([generator, discriminator],name=\"DCGAN\")\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=\"rmsprop\", metrics=['accuracy'])\n",
        "discriminator.trainable=False\n",
        "GAN.compile(loss='binary_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfqTiwQxSjnT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQMT-NemS0Rj"
      },
      "outputs": [],
      "source": [
        "neural_input=400\n",
        "noise = np.random.normal(0, 1, (batch_size, neural_input))#entrada de la red neuronal\n",
        "fake_data = generator.predict(noise)#como se general elementos a traves del generador(al principio sera ruido, pero cuando ya este entrenada la gan asi se generan las imagenes de los coches)\n",
        "view_samples(coches, 3,3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyR5yXvAqLLS"
      },
      "outputs": [],
      "source": [
        "# est ecodigo lo he sacado de aqui \n",
        "#https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/\n",
        "import matplotlib.pyplot as pyplot\n",
        "def plot_history(d1_hist, d2_hist, a1_hist, a2_hist):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(2, 1, 1)\n",
        "\tpyplot.plot(d1_hist, label='perdida discriminador')\n",
        "\t#pyplot.plot(a1_hist, label='Precision discriminador')\n",
        "\n",
        "\tpyplot.legend()\n",
        " \t###### el otro loss\n",
        "\n",
        "\tpyplot.subplot(2, 1, 2)\n",
        "\tpyplot.plot(d2_hist, label='perdida generador')\n",
        "\t#pyplot.plot(a2_hist, label='Gaccuracy')\n",
        "\tpyplot.legend()\n",
        " \n",
        "\t# plot discriminator accuracy\n",
        "\t#pyplot.subplot(2, 1, 1)\n",
        "\t#pyplot.plot(a1_hist, label='Daccuracy')\n",
        "\t#pyplot.plot(a2_hist, label='Gaccuracy')\n",
        "\t#pyplot.legend()\n",
        "\t# save plot to file\n",
        "\tpyplot.savefig('./plot_line_plot_loss.png')\n",
        "\tpyplot.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwC5NpXP52P6"
      },
      "outputs": [],
      "source": [
        "\n",
        "plot_history(dl,gl,da,ga)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu3ZzHbx8KLZ"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "print (\"media discriminador loss =\",numpy.mean(dl))\n",
        "print (\"media generador loss =\",numpy.mean(gl))\n",
        "print (\"varianza discriminador loss =\",numpy.var(dl))\n",
        "print (\"varianza generador loss =\",numpy.var(gl))\n",
        "\n",
        "\n",
        "print (\"media accuracy =\",numpy.mean(da))\n",
        "print (\"varianza accuracy  =\",numpy.var(da))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsR19QVCXQwL"
      },
      "outputs": [],
      "source": [
        "#este es el que va BIEN\n",
        "generadas=[]\n",
        "dl=[]\n",
        "da=[]\n",
        "gl=[]\n",
        "ga=[]\n",
        "ruidoo=tf.random.normal(shape=[1,neural_input])\n",
        "generada=generator.predict(ruidoo)\n",
        "i=0\n",
        "\n",
        "generator, discriminator= GAN.layers\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "     #reales\n",
        "     real = X_train[np.random.randint(0, tam_dataset, int(batch_size/2))]#cojo batch/2 veces numeros entre 0 y 8100\n",
        "\n",
        "     #fake\n",
        "     fake = generator.predict(tf.random.normal(shape=[int(batch_size/2),neural_input]))\n",
        "\n",
        "     #fake y real concatenados\n",
        "\n",
        "     #imagenes\n",
        "     fakeAndReal = tf.concat([fake,real], axis=0)\n",
        "     #resultados -> 0 es fake y 1 es real \n",
        "     y1= tf.constant([[0.]]*int(batch_size/2)+[[1.]]*int(batch_size/2))\n",
        "\n",
        "     #entrenamos el discriminador\n",
        "     discriminator.trainable=True\n",
        "     #disloss,disacc=discriminator.train_on_batch(fakeAndReal,y1)\n",
        "     discriminator.train_on_batch(fakeAndReal,y1)\n",
        "     #dl.append(disloss)\n",
        "     #da.append(disacc)\n",
        "\n",
        "     #y ahora el generador\n",
        "     #explicar mejor abajo, pero aqui le hacemos creer al discriminador que las imagenes son reales y solo cambiamos el \n",
        "    #generador para que cambie los pesos y entrene\n",
        "     #el generador se entrena solo con imagenes falsas, porque tienen que pasar por la entrada de tama√±o neural input aue es 400, las reales no se podria hacer eso \n",
        "     noise=tf.random.normal(shape=[batch_size,neural_input])\n",
        "     y2= tf.constant([[1.]]*batch_size)\n",
        "     discriminator.trainable=False\n",
        "     #genloss,genacc=GAN.train_on_batch(noise,y2)\n",
        "     GAN.train_on_batch(noise,y2)\n",
        "\n",
        "     #gl.append(genloss)\n",
        "     #ga.append(genacc)\n",
        "\n",
        "\n",
        "      #cosas necesarias para:\n",
        "      #ver las imagenes cada ciertas epochs\n",
        "      #guardar imagenes para poder hacer gifts\n",
        "     if (epoch==1) | ((epoch+1) % show_interval == 0):\n",
        "        #print (\"%d [Discriminator acc.: %.2f%%] [Generator loss: %f]\" % (epoch+1, 100*D_loss[1], G_loss))\n",
        "        print(epoch)\n",
        "        #print(\"perdida discriminador \",disloss, \"perdida generador\", genloss,\"precision discriminador \",disacc)\n",
        "        #print(\"precision discriminador \",disacc)#, \"acc generador\", genacc)\n",
        "        #noise = np.random.normal(0, 1, (5, neural_input))\n",
        "        #view_samples(generator.predict(noise), 1,5) \n",
        "        generada=generator.predict(ruidoo)\n",
        "        generadas.append(generada)#cambiar algo[0] por generada \n",
        "        output='/content/prueba'+str(i)+'.jpeg'\n",
        "  \n",
        "        plt.imsave(output, generada)\n",
        "        i=i+1\n",
        "        \n",
        "\n",
        "\n",
        "noise=tf.random.normal(shape=[batch_size,neural_input])\n",
        "cosa=generator.predict(noise)\n",
        "view_samples(cosa, 5,5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPCZqrx4UTPv"
      },
      "outputs": [],
      "source": [
        "cosa=generator.predict(noise)\n",
        "resul=[]\n",
        "#cosa=(cosa+1)/2\n",
        "#cosa[1][20]\n",
        "view_samples(generadas, 10,8) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgyVmWu403O5"
      },
      "source": [
        "# Para crear un gift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2LAFIF5MUn5"
      },
      "outputs": [],
      "source": [
        "generadas=np.array(generadas)\n",
        "i=1\n",
        "for g in generadas:\n",
        "  g=(g+1)/2\n",
        "  cosa2=g.reshape(56,56,3)\n",
        "  output='/content/eee'+str(i)+'.jpeg'\n",
        "  plt.imsave(output, cosa2)\n",
        "  i=i*10+1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEMklajrv97a"
      },
      "outputs": [],
      "source": [
        "\n",
        "filenames = glob.glob('eee*.jpeg')\n",
        "filenames = sorted(filenames)\n",
        "i=1\n",
        "for filename in filenames:\n",
        "  \n",
        "    img = cv2.imread(filename, 1)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "\n",
        "    img_scale_up = cv2.resize(img, (0, 0), fx=10, fy=10)\n",
        "\n",
        "\n",
        "    output='/content/eee'+str(i)+'.jpeg'\n",
        "    plt.imsave(output, img_scale_up)\n",
        "    i=i*10+1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NJYaI2CRjMD"
      },
      "outputs": [],
      "source": [
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  \n",
        "  #filenames = glob.glob('_44*.jpg')\n",
        "  filenames = glob.glob('eee*.jpeg')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    print(\"hola\")\n",
        "    print(filename)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z37mIBERmdJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install git+https://github.com/tensorflow/docs\n",
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzLPEVg9OiNX"
      },
      "outputs": [],
      "source": [
        "files.download('./dcgan.gif')\n",
        "%cd /content/\n",
        "#!ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
